{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde3580f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:19.727759Z",
     "iopub.status.busy": "2022-03-13T02:22:19.726914Z",
     "iopub.status.idle": "2022-03-13T02:22:19.730910Z",
     "shell.execute_reply": "2022-03-13T02:22:19.730409Z",
     "shell.execute_reply.started": "2022-03-13T01:48:50.711797Z"
    },
    "papermill": {
     "duration": 0.050227,
     "end_time": "2022-03-13T02:22:19.731032",
     "exception": false,
     "start_time": "2022-03-13T02:22:19.680805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# DECLARE HOW MANY GPUS YOU WISH TO USE. \n",
    "# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n",
    "\n",
    "# VERSION FOR SAVING/LOADING MODEL WEIGHTS\n",
    "# THIS SHOULD MATCH THE MODEL IN LOAD_MODEL_FROM\n",
    "VER=14 \n",
    "\n",
    "# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n",
    "# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\n",
    "LOAD_TOKENS_FROM =  '../input/tf-longformer-v12'\n",
    "\n",
    "# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n",
    "# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\n",
    "LOAD_MODEL_FROM = None\n",
    "\n",
    "# IF FOLLOWING IS NONE, THEN NOTEBOOK \n",
    "# USES INTERNET AND DOWNLOADS HUGGINGFACE \n",
    "# CONFIG, TOKENIZER, AND MODEL\n",
    "DOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n",
    "\n",
    "if DOWNLOADED_MODEL_PATH is None:\n",
    "    DOWNLOADED_MODEL_PATH = 'model'    \n",
    "MODEL_NAME = 'allenai/longformer-base-4096'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd49d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:19.877018Z",
     "iopub.status.busy": "2022-03-13T02:22:19.875187Z",
     "iopub.status.idle": "2022-03-13T02:22:19.879418Z",
     "shell.execute_reply": "2022-03-13T02:22:19.878902Z",
     "shell.execute_reply.started": "2022-03-13T01:48:51.395565Z"
    },
    "papermill": {
     "duration": 0.042007,
     "end_time": "2022-03-13T02:22:19.879525",
     "exception": false,
     "start_time": "2022-03-13T02:22:19.837518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DOWNLOADED_MODEL_PATH == 'model':\n",
    "    os.mkdir('model')\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.save_pretrained('model')\n",
    "\n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME) \n",
    "    config.save_pretrained('model')\n",
    "\n",
    "    backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n",
    "    backbone.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1dded",
   "metadata": {
    "papermill": {
     "duration": 0.038006,
     "end_time": "2022-03-13T02:22:20.023192",
     "exception": false,
     "start_time": "2022-03-13T02:22:19.985186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ceb839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:20.097678Z",
     "iopub.status.busy": "2022-03-13T02:22:20.097116Z",
     "iopub.status.idle": "2022-03-13T02:22:31.105476Z",
     "shell.execute_reply": "2022-03-13T02:22:31.106420Z",
     "shell.execute_reply.started": "2022-03-13T01:48:52.494377Z"
    },
    "papermill": {
     "duration": 11.048311,
     "end_time": "2022-03-13T02:22:31.106607",
     "exception": false,
     "start_time": "2022-03-13T02:22:20.058296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.6.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from transformers import *\n",
    "print('TF version',tf.__version__)\n",
    "from tensorflow_addons.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722dab03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:31.195658Z",
     "iopub.status.busy": "2022-03-13T02:22:31.194344Z",
     "iopub.status.idle": "2022-03-13T02:22:31.208704Z",
     "shell.execute_reply": "2022-03-13T02:22:31.209312Z",
     "shell.execute_reply.started": "2022-03-13T01:49:02.869364Z"
    },
    "papermill": {
     "duration": 0.058976,
     "end_time": "2022-03-13T02:22:31.209473",
     "exception": false,
     "start_time": "2022-03-13T02:22:31.150497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single strategy\n"
     ]
    }
   ],
   "source": [
    "# USE MULTIPLE GPUS\n",
    "if os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('single strategy')\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('multiple strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ac3ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:31.292308Z",
     "iopub.status.busy": "2022-03-13T02:22:31.291360Z",
     "iopub.status.idle": "2022-03-13T02:22:31.297438Z",
     "shell.execute_reply": "2022-03-13T02:22:31.296980Z",
     "shell.execute_reply.started": "2022-03-13T01:49:02.884528Z"
    },
    "papermill": {
     "duration": 0.048417,
     "end_time": "2022-03-13T02:22:31.297624",
     "exception": false,
     "start_time": "2022-03-13T02:22:31.249207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision enabled\n"
     ]
    }
   ],
   "source": [
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "print('Mixed precision enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098bd60",
   "metadata": {
    "papermill": {
     "duration": 0.037779,
     "end_time": "2022-03-13T02:22:31.374913",
     "exception": false,
     "start_time": "2022-03-13T02:22:31.337134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e9f62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:31.450459Z",
     "iopub.status.busy": "2022-03-13T02:22:31.449823Z",
     "iopub.status.idle": "2022-03-13T02:22:33.028031Z",
     "shell.execute_reply": "2022-03-13T02:22:33.028588Z",
     "shell.execute_reply.started": "2022-03-13T01:49:02.894170Z"
    },
    "papermill": {
     "duration": 1.618235,
     "end_time": "2022-03-13T02:22:33.028760",
     "exception": false,
     "start_time": "2022-03-13T02:22:31.410525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/feedback-prize-2021/train.csv')\n",
    "print( train.shape )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08858e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:33.124387Z",
     "iopub.status.busy": "2022-03-13T02:22:33.123679Z",
     "iopub.status.idle": "2022-03-13T02:22:33.131485Z",
     "shell.execute_reply": "2022-03-13T02:22:33.132026Z",
     "shell.execute_reply.started": "2022-03-13T01:49:04.612417Z"
    },
    "papermill": {
     "duration": 0.061617,
     "end_time": "2022-03-13T02:22:33.132200",
     "exception": false,
     "start_time": "2022-03-13T02:22:33.070583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train labels are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
       "       'Counterclaim', 'Rebuttal'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The train labels are:')\n",
    "train.discourse_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a61f731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:33.219284Z",
     "iopub.status.busy": "2022-03-13T02:22:33.218575Z",
     "iopub.status.idle": "2022-03-13T02:22:33.226167Z",
     "shell.execute_reply": "2022-03-13T02:22:33.226759Z",
     "shell.execute_reply.started": "2022-03-13T01:49:04.638115Z"
    },
    "papermill": {
     "duration": 0.056515,
     "end_time": "2022-03-13T02:22:33.226934",
     "exception": false,
     "start_time": "2022-03-13T02:22:33.170419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 train texts.\n"
     ]
    }
   ],
   "source": [
    "IDS = train.id.unique()\n",
    "print('There are',len(IDS),'train texts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386c1b9",
   "metadata": {
    "papermill": {
     "duration": 0.036827,
     "end_time": "2022-03-13T02:22:33.301781",
     "exception": false,
     "start_time": "2022-03-13T02:22:33.264954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24082bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:33.386684Z",
     "iopub.status.busy": "2022-03-13T02:22:33.386103Z",
     "iopub.status.idle": "2022-03-13T02:22:33.513569Z",
     "shell.execute_reply": "2022-03-13T02:22:33.513043Z",
     "shell.execute_reply.started": "2022-03-13T01:49:04.658871Z"
    },
    "papermill": {
     "duration": 0.174376,
     "end_time": "2022-03-13T02:22:33.513695",
     "exception": false,
     "start_time": "2022-03-13T02:22:33.339319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "\n",
    "# THE TOKENS AND ATTENTION ARRAYS\n",
    "tokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\n",
    "train_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n",
    "train_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n",
    "\n",
    "# THE 14 CLASSES FOR NER\n",
    "lead_b = np.zeros((len(IDS),MAX_LEN))\n",
    "lead_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "position_b = np.zeros((len(IDS),MAX_LEN))\n",
    "position_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "evidence_b = np.zeros((len(IDS),MAX_LEN))\n",
    "evidence_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "claim_b = np.zeros((len(IDS),MAX_LEN))\n",
    "claim_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "conclusion_b = np.zeros((len(IDS),MAX_LEN))\n",
    "conclusion_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "counterclaim_b = np.zeros((len(IDS),MAX_LEN))\n",
    "counterclaim_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "rebuttal_b = np.zeros((len(IDS),MAX_LEN))\n",
    "rebuttal_i = np.zeros((len(IDS),MAX_LEN))\n",
    "\n",
    "# HELPER VARIABLES\n",
    "train_lens = []\n",
    "targets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\n",
    "targets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\n",
    "target_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n",
    "             'Counterclaim':5, 'Rebuttal':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2706662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:33.593981Z",
     "iopub.status.busy": "2022-03-13T02:22:33.592734Z",
     "iopub.status.idle": "2022-03-13T02:22:33.596395Z",
     "shell.execute_reply": "2022-03-13T02:22:33.596825Z",
     "shell.execute_reply.started": "2022-03-13T01:49:04.796404Z"
    },
    "papermill": {
     "duration": 0.045627,
     "end_time": "2022-03-13T02:22:33.596948",
     "exception": false,
     "start_time": "2022-03-13T02:22:33.551321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='../input/tf-longformer-v12', vocab_size=50265, model_max_len=4096, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eae9c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:33.686084Z",
     "iopub.status.busy": "2022-03-13T02:22:33.685340Z",
     "iopub.status.idle": "2022-03-13T02:22:36.001302Z",
     "shell.execute_reply": "2022-03-13T02:22:36.000537Z",
     "shell.execute_reply.started": "2022-03-13T01:49:04.804572Z"
    },
    "papermill": {
     "duration": 2.3669,
     "end_time": "2022-03-13T02:22:36.001446",
     "exception": false,
     "start_time": "2022-03-13T02:22:33.634546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WE ASSUME DATAFRAME IS ASCENDING WHICH IT IS\n",
    "assert( np.sum(train.groupby('id')['discourse_start'].diff()<=0)==0 )\n",
    "\n",
    "# FOR LOOP THROUGH EACH TRAIN TEXT\n",
    "for id_num in range(len(IDS)):\n",
    "    if LOAD_TOKENS_FROM: break\n",
    "    if id_num%100==0: print(id_num,', ',end='')\n",
    "        \n",
    "    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n",
    "    n = IDS[id_num]\n",
    "    name = f'../input/feedback-prize-2021/train/{n}.txt'\n",
    "    txt = open(name, 'r').read()\n",
    "    train_lens.append( len(txt.split()))\n",
    "    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
    "                                   truncation=True, return_offsets_mapping=True)\n",
    "    train_tokens[id_num,] = tokens['input_ids']\n",
    "    train_attention[id_num,] = tokens['attention_mask']\n",
    "    \n",
    "    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n",
    "    offsets = tokens['offset_mapping']\n",
    "    offset_index = 0\n",
    "    df = train.loc[train.id==n]\n",
    "    for index,row in df.iterrows():\n",
    "        a = row.discourse_start\n",
    "        b = row.discourse_end\n",
    "        if offset_index>len(offsets)-1:\n",
    "            break\n",
    "        c = offsets[offset_index][0]\n",
    "        d = offsets[offset_index][1]\n",
    "        beginning = True\n",
    "        while b>c:\n",
    "            if (c>=a)&(b>=d):\n",
    "                k = target_map[row.discourse_type]\n",
    "                if beginning:\n",
    "                    targets_b[k][id_num][offset_index] = 1\n",
    "                    beginning = False\n",
    "                else:\n",
    "                    targets_i[k][id_num][offset_index] = 1\n",
    "            offset_index += 1\n",
    "            if offset_index>len(offsets)-1:\n",
    "                break\n",
    "            c = offsets[offset_index][0]\n",
    "            d = offsets[offset_index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cad1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:36.166832Z",
     "iopub.status.busy": "2022-03-13T02:22:36.166124Z",
     "iopub.status.idle": "2022-03-13T02:22:36.169168Z",
     "shell.execute_reply": "2022-03-13T02:22:36.168637Z",
     "shell.execute_reply.started": "2022-03-13T01:49:10.366827Z"
    },
    "papermill": {
     "duration": 0.044759,
     "end_time": "2022-03-13T02:22:36.169289",
     "exception": false,
     "start_time": "2022-03-13T02:22:36.124530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_TOKENS_FROM is None:\n",
    "    plt.hist(train_lens,bins=100, color = 'g')\n",
    "    plt.title('Histogram of Train Word Counts',size=16)\n",
    "    plt.xlabel('Train Word Count',size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be46458e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:36.325531Z",
     "iopub.status.busy": "2022-03-13T02:22:36.324732Z",
     "iopub.status.idle": "2022-03-13T02:22:36.326709Z",
     "shell.execute_reply": "2022-03-13T02:22:36.327135Z",
     "shell.execute_reply.started": "2022-03-13T01:49:11.147836Z"
    },
    "papermill": {
     "duration": 0.044983,
     "end_time": "2022-03-13T02:22:36.327255",
     "exception": false,
     "start_time": "2022-03-13T02:22:36.282272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_TOKENS_FROM is None:\n",
    "    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n",
    "    for k in range(7):\n",
    "        targets[:,:,2*k] = targets_b[k]\n",
    "        targets[:,:,2*k+1] = targets_i[k]\n",
    "    targets[:,:,14] = 1-np.max(targets,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66bc81b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:36.405890Z",
     "iopub.status.busy": "2022-03-13T02:22:36.405179Z",
     "iopub.status.idle": "2022-03-13T02:22:36.407148Z",
     "shell.execute_reply": "2022-03-13T02:22:36.407555Z",
     "shell.execute_reply.started": "2022-03-13T01:49:11.563675Z"
    },
    "papermill": {
     "duration": 0.042888,
     "end_time": "2022-03-13T02:22:36.407679",
     "exception": false,
     "start_time": "2022-03-13T02:22:36.364791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd22a263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:36.488334Z",
     "iopub.status.busy": "2022-03-13T02:22:36.487790Z",
     "iopub.status.idle": "2022-03-13T02:22:42.941746Z",
     "shell.execute_reply": "2022-03-13T02:22:42.942529Z",
     "shell.execute_reply.started": "2022-03-13T01:49:12.869835Z"
    },
    "papermill": {
     "duration": 6.496695,
     "end_time": "2022-03-13T02:22:42.942724",
     "exception": false,
     "start_time": "2022-03-13T02:22:36.446029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NER tokens\n"
     ]
    }
   ],
   "source": [
    "if LOAD_TOKENS_FROM is None:\n",
    "    np.save(f'targets_{MAX_LEN}', targets)\n",
    "    np.save(f'tokens_{MAX_LEN}', train_tokens)\n",
    "    np.save(f'attention_{MAX_LEN}', train_attention)\n",
    "    print('Saved NER tokens')\n",
    "else:\n",
    "    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n",
    "    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n",
    "    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n",
    "    print('Loaded NER tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9ffa622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.034239Z",
     "iopub.status.busy": "2022-03-13T02:22:43.033489Z",
     "iopub.status.idle": "2022-03-13T02:22:43.046143Z",
     "shell.execute_reply": "2022-03-13T02:22:43.046585Z",
     "shell.execute_reply.started": "2022-03-13T01:49:19.598483Z"
    },
    "papermill": {
     "duration": 0.064434,
     "end_time": "2022-03-13T02:22:43.046762",
     "exception": false,
     "start_time": "2022-03-13T02:22:42.982328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 48083, 50118, ...,     1,     1,     1],\n",
       "       [    0, 48083,   359, ...,     1,     1,     1],\n",
       "       [    0, 40216, 12091, ...,     1,     1,     1],\n",
       "       ...,\n",
       "       [    0, 31206,  1818, ...,     1,     1,     1],\n",
       "       [    0,   970,    34, ...,     1,     1,     1],\n",
       "       [    0,  1121,  8178, ...,   768,     6,     2]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3133dda",
   "metadata": {
    "papermill": {
     "duration": 0.076468,
     "end_time": "2022-03-13T02:22:43.198592",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.122124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model\n",
    "We will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a `B` class and `I` class for each of 7 labels. And we have an additional class (called `O` class) for tokens that do not belong to one of the 14 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198cf780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.353797Z",
     "iopub.status.busy": "2022-03-13T02:22:43.352903Z",
     "iopub.status.idle": "2022-03-13T02:22:43.354878Z",
     "shell.execute_reply": "2022-03-13T02:22:43.355553Z",
     "shell.execute_reply.started": "2022-03-13T00:18:58.636263Z"
    },
    "papermill": {
     "duration": 0.079544,
     "end_time": "2022-03-13T02:22:43.355735",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.276191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n",
    "    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n",
    "    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n",
    "    \n",
    "    x = backbone(tokens, attention_mask=attention)\n",
    "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=256, kernel_size=8, activation='relu'))(x[0])\n",
    "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D(pool_size=2))(x)\n",
    "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x[0])\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Dropout(0.75)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1.2e-4),\n",
    "                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n",
    "                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea8488f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.486963Z",
     "iopub.status.busy": "2022-03-13T02:22:43.486153Z",
     "iopub.status.idle": "2022-03-13T02:22:43.489025Z",
     "shell.execute_reply": "2022-03-13T02:22:43.488403Z",
     "shell.execute_reply.started": "2022-03-13T00:18:58.649635Z"
    },
    "papermill": {
     "duration": 0.068169,
     "end_time": "2022-03-13T02:22:43.489179",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.421010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f1d09dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.616565Z",
     "iopub.status.busy": "2022-03-13T02:22:43.615734Z",
     "iopub.status.idle": "2022-03-13T02:22:43.618184Z",
     "shell.execute_reply": "2022-03-13T02:22:43.617759Z",
     "shell.execute_reply.started": "2022-03-13T00:19:41.454814Z"
    },
    "papermill": {
     "duration": 0.067023,
     "end_time": "2022-03-13T02:22:43.618287",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.551264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c6f25",
   "metadata": {
    "papermill": {
     "duration": 0.038017,
     "end_time": "2022-03-13T02:22:43.694350",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.656333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f9fa58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.775860Z",
     "iopub.status.busy": "2022-03-13T02:22:43.775048Z",
     "iopub.status.idle": "2022-03-13T02:22:43.776984Z",
     "shell.execute_reply": "2022-03-13T02:22:43.777525Z",
     "shell.execute_reply.started": "2022-03-13T01:49:19.609878Z"
    },
    "papermill": {
     "duration": 0.04511,
     "end_time": "2022-03-13T02:22:43.777655",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.732545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4 \n",
    "LRS = [0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5] \n",
    "def lrfn(epoch):\n",
    "    return LRS[epoch]\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6971bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.861928Z",
     "iopub.status.busy": "2022-03-13T02:22:43.861157Z",
     "iopub.status.idle": "2022-03-13T02:22:43.868829Z",
     "shell.execute_reply": "2022-03-13T02:22:43.869416Z",
     "shell.execute_reply.started": "2022-03-13T01:49:19.619741Z"
    },
    "papermill": {
     "duration": 0.05313,
     "end_time": "2022-03-13T02:22:43.869588",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.816458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 14034 , Valid size 1560\n"
     ]
    }
   ],
   "source": [
    "# TRAIN VALID SPLIT 90% 10%\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n",
    "valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n",
    "np.random.seed(None)\n",
    "print('Train size',len(train_idx),', Valid size',len(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae1a5ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:43.952139Z",
     "iopub.status.busy": "2022-03-13T02:22:43.950583Z",
     "iopub.status.idle": "2022-03-13T02:22:43.952820Z",
     "shell.execute_reply": "2022-03-13T02:22:43.953213Z"
    },
    "papermill": {
     "duration": 0.044555,
     "end_time": "2022-03-13T02:22:43.953333",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.908778",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # LOAD MODEL\n",
    "# if LOAD_MODEL_FROM:\n",
    "#     model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n",
    "    \n",
    "# # OR TRAIN MODEL\n",
    "# else:\n",
    "#     model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n",
    "#           y = targets[train_idx,],\n",
    "#           validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n",
    "#                              targets[valid_idx,]),\n",
    "#           callbacks = [lr_callback],\n",
    "#           epochs = EPOCHS,\n",
    "#           batch_size = BATCH_SIZE,\n",
    "#           verbose = 2)\n",
    "\n",
    "#     # SAVE MODEL WEIGHTS\n",
    "#     model.save_weights(f'long_v{VER}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57608f08",
   "metadata": {
    "papermill": {
     "duration": 0.038792,
     "end_time": "2022-03-13T02:22:44.030724",
     "exception": false,
     "start_time": "2022-03-13T02:22:43.991932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validate Model - Infer OOF\n",
    "We will now make predictions on the validation texts. Our model makes label predictions for each token, we need to convert this into a list of word indices for each label. Note that the tokens and words are not the same. A single word may be broken into multiple tokens. Therefore we need to first create a map to change token indices to word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b7ddf31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:44.117017Z",
     "iopub.status.busy": "2022-03-13T02:22:44.116255Z",
     "iopub.status.idle": "2022-03-13T02:22:44.118259Z",
     "shell.execute_reply": "2022-03-13T02:22:44.118785Z",
     "shell.execute_reply.started": "2022-03-13T01:49:22.413196Z"
    },
    "papermill": {
     "duration": 0.0493,
     "end_time": "2022-03-13T02:22:44.118918",
     "exception": false,
     "start_time": "2022-03-13T02:22:44.069618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    \n",
    "    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n",
    "    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n",
    "    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n",
    "    \n",
    "    x = backbone(tokens, attention_mask=attention)\n",
    "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=256, kernel_size=8, activation='relu'))(x[0])\n",
    "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D(pool_size=2))(x)\n",
    "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x[0])\n",
    "    x = tf.keras.layers.Dropout(0.75)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1.2e-4),\n",
    "                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n",
    "                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2bb174b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:44.204045Z",
     "iopub.status.busy": "2022-03-13T02:22:44.202538Z",
     "iopub.status.idle": "2022-03-13T02:22:44.204652Z",
     "shell.execute_reply": "2022-03-13T02:22:44.205057Z",
     "shell.execute_reply.started": "2022-03-13T01:49:22.851485Z"
    },
    "papermill": {
     "duration": 0.048005,
     "end_time": "2022-03-13T02:22:44.205174",
     "exception": false,
     "start_time": "2022-03-13T02:22:44.157169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model3():\n",
    "    \n",
    "    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n",
    "    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n",
    "    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n",
    "    \n",
    "    x = backbone(tokens, attention_mask=attention)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n",
    "    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1.2e-4),\n",
    "                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n",
    "                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96273f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:22:44.286599Z",
     "iopub.status.busy": "2022-03-13T02:22:44.286072Z",
     "iopub.status.idle": "2022-03-13T02:23:59.782857Z",
     "shell.execute_reply": "2022-03-13T02:23:59.782302Z",
     "shell.execute_reply.started": "2022-03-13T01:49:23.381811Z"
    },
    "papermill": {
     "duration": 75.539528,
     "end_time": "2022-03-13T02:23:59.782998",
     "exception": false,
     "start_time": "2022-03-13T02:22:44.243470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFLongformerModel.\n",
      "\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at ../input/tf-longformer-v12/tf_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "All model checkpoint layers were used when initializing TFLongformerModel.\n",
      "\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at ../input/tf-longformer-v12/tf_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFLongformerModel.\n",
      "\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at ../input/tf-longformer-v12/tf_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model1 = build_model1()\n",
    "    model2 = build_model1()\n",
    "    model3 = build_model3()\n",
    "model1.load_weights('../input/my-model/long_1.h5')\n",
    "model2.load_weights('../input/my-model/long_2.h5')\n",
    "model3.load_weights( '../input/tflongformerv14/long_v14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb41bfd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:23:59.872207Z",
     "iopub.status.busy": "2022-03-13T02:23:59.871302Z",
     "iopub.status.idle": "2022-03-13T02:34:22.528752Z",
     "shell.execute_reply": "2022-03-13T02:34:22.529168Z",
     "shell.execute_reply.started": "2022-03-13T01:50:42.480472Z"
    },
    "papermill": {
     "duration": 622.70473,
     "end_time": "2022-03-13T02:34:22.529326",
     "exception": false,
     "start_time": "2022-03-13T02:23:59.824596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 190s\n",
      "98/98 - 190s\n",
      "98/98 - 186s\n",
      "OOF predictions shape: (1560, 1024, 15)\n"
     ]
    }
   ],
   "source": [
    "p = model1.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n",
    "                  batch_size=16, verbose=2) / 3\n",
    "p += model2.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n",
    "                  batch_size=16, verbose=2) / 3\n",
    "p += model3.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n",
    "                  batch_size=16, verbose=2) / 3\n",
    "print('OOF predictions shape:',p.shape)\n",
    "oof_preds = np.argmax(p,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f033dca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:22.616954Z",
     "iopub.status.busy": "2022-03-13T02:34:22.616203Z",
     "iopub.status.idle": "2022-03-13T02:34:22.623443Z",
     "shell.execute_reply": "2022-03-13T02:34:22.623899Z",
     "shell.execute_reply.started": "2022-03-13T02:00:43.012331Z"
    },
    "papermill": {
     "duration": 0.053211,
     "end_time": "2022-03-13T02:34:22.624022",
     "exception": false,
     "start_time": "2022-03-13T02:34:22.570811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.05433795e-03, 4.62535158e-04, 4.28258645e-04, ...,\n",
       "         4.33532405e-05, 7.68234459e-05, 9.93755460e-01],\n",
       "        [2.76727340e-04, 2.67172290e-04, 9.60785546e-05, ...,\n",
       "         9.57642715e-06, 2.32446291e-05, 9.97745693e-01],\n",
       "        [1.53510089e-04, 2.71800760e-04, 4.32187226e-05, ...,\n",
       "         4.96544908e-06, 1.64801277e-05, 9.98322725e-01],\n",
       "        ...,\n",
       "        [3.01030866e-07, 4.52098948e-06, 8.31199088e-07, ...,\n",
       "         3.90195680e-07, 3.70143061e-06, 9.97122884e-01],\n",
       "        [6.35746574e-07, 8.24387553e-06, 1.70448754e-06, ...,\n",
       "         7.89754324e-07, 6.56896782e-06, 9.96466875e-01],\n",
       "        [3.42809130e-06, 3.63133404e-05, 9.13522945e-06, ...,\n",
       "         4.49496201e-06, 2.61350579e-05, 9.93576050e-01]],\n",
       "\n",
       "       [[2.78245002e-01, 4.88187373e-03, 3.85761517e-03, ...,\n",
       "         4.38704912e-04, 3.33419332e-04, 7.01429188e-01],\n",
       "        [6.55631348e-03, 1.87689200e-01, 6.87434804e-04, ...,\n",
       "         4.41936863e-05, 1.29439650e-04, 7.98643708e-01],\n",
       "        [5.85144327e-04, 3.29622060e-01, 1.74397646e-04, ...,\n",
       "         5.17871240e-06, 4.85481360e-05, 6.65735483e-01],\n",
       "        ...,\n",
       "        [3.01617206e-07, 4.52313725e-06, 8.32775697e-07, ...,\n",
       "         3.90811067e-07, 3.70255998e-06, 9.97121453e-01],\n",
       "        [6.36953359e-07, 8.24846484e-06, 1.70736223e-06, ...,\n",
       "         7.90853903e-07, 6.57094824e-06, 9.96464968e-01],\n",
       "        [3.43440956e-06, 3.63387262e-05, 9.14677003e-06, ...,\n",
       "         4.49912022e-06, 2.61436035e-05, 9.93571401e-01]],\n",
       "\n",
       "       [[9.88900661e-01, 3.34379706e-03, 1.78798242e-03, ...,\n",
       "         8.29268465e-05, 6.78925717e-05, 2.10773177e-03],\n",
       "        [1.26637367e-03, 9.94436264e-01, 1.23896010e-04, ...,\n",
       "         3.81414429e-06, 1.13541042e-04, 9.32214025e-04],\n",
       "        [4.67115970e-05, 9.98381615e-01, 1.60131367e-05, ...,\n",
       "         4.69781725e-07, 4.13408998e-05, 4.07437008e-04],\n",
       "        ...,\n",
       "        [3.16690915e-07, 4.66824895e-06, 8.56272152e-07, ...,\n",
       "         4.51227265e-07, 3.90941887e-06, 9.96935487e-01],\n",
       "        [6.70172540e-07, 8.49648040e-06, 1.71362024e-06, ...,\n",
       "         9.04464343e-07, 6.91443847e-06, 9.96256709e-01],\n",
       "        [3.60333092e-06, 3.75708150e-05, 9.10031576e-06, ...,\n",
       "         5.07528557e-06, 2.77830550e-05, 9.93149638e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[9.93201792e-01, 2.63249315e-03, 1.00944401e-03, ...,\n",
       "         6.21748477e-05, 3.59907972e-05, 1.44266151e-03],\n",
       "        [1.26053847e-03, 9.96031642e-01, 1.19086544e-04, ...,\n",
       "         3.17043532e-06, 5.39739776e-05, 7.07810279e-04],\n",
       "        [6.93165566e-05, 9.99003768e-01, 2.00444447e-05, ...,\n",
       "         4.70657710e-07, 1.82346685e-05, 3.14166566e-04],\n",
       "        ...,\n",
       "        [3.04862442e-06, 3.26504261e-04, 4.39846262e-05, ...,\n",
       "         3.21435582e-05, 1.29160215e-03, 5.40429056e-02],\n",
       "        [6.26065821e-06, 5.85086236e-04, 9.23336775e-05, ...,\n",
       "         4.88587393e-05, 1.54903019e-03, 7.89935887e-02],\n",
       "        [4.39782016e-05, 8.05450371e-04, 3.16575228e-04, ...,\n",
       "         6.23609740e-05, 5.17399923e-04, 8.63769293e-01]],\n",
       "\n",
       "       [[9.69998002e-01, 1.57976081e-03, 2.27308553e-02, ...,\n",
       "         1.01802019e-04, 5.56098639e-05, 2.69133900e-03],\n",
       "        [8.77590675e-04, 9.61451530e-01, 5.57236257e-04, ...,\n",
       "         7.20872140e-06, 1.32447385e-04, 3.83579126e-03],\n",
       "        [4.87922152e-05, 9.74994957e-01, 9.54352145e-05, ...,\n",
       "         1.40683528e-06, 5.82569992e-05, 2.07679183e-03],\n",
       "        ...,\n",
       "        [3.00395982e-07, 4.52029190e-06, 8.30410897e-07, ...,\n",
       "         3.89495995e-07, 3.70108773e-06, 9.97123659e-01],\n",
       "        [6.34535013e-07, 8.24166364e-06, 1.70278634e-06, ...,\n",
       "         7.88470800e-07, 6.56808197e-06, 9.96467769e-01],\n",
       "        [3.42177805e-06, 3.62987921e-05, 9.13015174e-06, ...,\n",
       "         4.49004119e-06, 2.61301175e-05, 9.93578315e-01]],\n",
       "\n",
       "       [[9.69404340e-01, 1.68269698e-03, 2.28878967e-02, ...,\n",
       "         1.07422151e-04, 5.54165017e-05, 3.56583903e-03],\n",
       "        [1.47901743e-03, 9.67455506e-01, 6.98137039e-04, ...,\n",
       "         1.02131553e-05, 2.21003895e-04, 7.72843137e-03],\n",
       "        [9.01199164e-05, 9.76965547e-01, 1.72169122e-04, ...,\n",
       "         1.93866458e-06, 8.69197320e-05, 4.14453167e-03],\n",
       "        ...,\n",
       "        [3.01159190e-07, 4.52297991e-06, 8.32522517e-07, ...,\n",
       "         3.90095977e-07, 3.70377120e-06, 9.97121513e-01],\n",
       "        [6.36440916e-07, 8.24778999e-06, 1.70579449e-06, ...,\n",
       "         7.89371313e-07, 6.57265855e-06, 9.96464968e-01],\n",
       "        [3.43100396e-06, 3.63301842e-05, 9.14276006e-06, ...,\n",
       "         4.49401568e-06, 2.61512268e-05, 9.93569851e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03eb1e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:22.711279Z",
     "iopub.status.busy": "2022-03-13T02:34:22.710630Z",
     "iopub.status.idle": "2022-03-13T02:34:22.713158Z",
     "shell.execute_reply": "2022-03-13T02:34:22.712768Z",
     "shell.execute_reply.started": "2022-03-13T02:00:43.025589Z"
    },
    "papermill": {
     "duration": 0.047612,
     "end_time": "2022-03-13T02:34:22.713260",
     "exception": false,
     "start_time": "2022-03-13T02:34:22.665648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n",
    "             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f1d1e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:22.813065Z",
     "iopub.status.busy": "2022-03-13T02:34:22.812238Z",
     "iopub.status.idle": "2022-03-13T02:34:22.814701Z",
     "shell.execute_reply": "2022-03-13T02:34:22.814226Z",
     "shell.execute_reply.started": "2022-03-13T02:00:43.032007Z"
    },
    "papermill": {
     "duration": 0.060075,
     "end_time": "2022-03-13T02:34:22.814807",
     "exception": false,
     "start_time": "2022-03-13T02:34:22.754732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n",
    "    all_predictions = []\n",
    "\n",
    "    for id_num in range(len(preds)):\n",
    "    \n",
    "        # GET ID\n",
    "        if (id_num%100==0)&(verbose): \n",
    "            print(id_num,', ',end='')\n",
    "        n = text_ids[id_num]\n",
    "    \n",
    "        # GET TOKEN POSITIONS IN CHARS\n",
    "        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n",
    "        txt = open(name, 'r').read()\n",
    "        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
    "                                   truncation=True, return_offsets_mapping=True)\n",
    "        off = tokens['offset_mapping']\n",
    "    \n",
    "        # GET WORD POSITIONS IN CHARS\n",
    "        w = []\n",
    "        blank = True\n",
    "        for i in range(len(txt)):\n",
    "            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n",
    "                w.append(i)\n",
    "                blank=False\n",
    "            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n",
    "                blank=True\n",
    "        w.append(1e6)\n",
    "            \n",
    "        # MAPPING FROM TOKENS TO WORDS\n",
    "        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n",
    "        w_i = 0\n",
    "        for i in range(len(off)):\n",
    "            if off[i][1]==0: continue\n",
    "            while off[i][0]>=w[w_i+1]: w_i += 1\n",
    "            word_map[i] = int(w_i)\n",
    "        \n",
    "        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n",
    "        ### KEY: ###\n",
    "        # 0: LEAD_B, 1: LEAD_I\n",
    "        # 2: POSITION_B, 3: POSITION_I\n",
    "        # 4: EVIDENCE_B, 5: EVIDENCE_I\n",
    "        # 6: CLAIM_B, 7: CLAIM_I\n",
    "        # 8: CONCLUSION_B, 9: CONCLUSION_I\n",
    "        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n",
    "        # 12: REBUTTAL_B, 13: REBUTTAL_I\n",
    "        # 14: NOTHING i.e. O\n",
    "        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n",
    "        pred = preds[id_num,]/2.0\n",
    "    \n",
    "        i = 0\n",
    "        while i<MAX_LEN:\n",
    "            prediction = []\n",
    "            start = pred[i]\n",
    "            if start in [0,1,2,3,4,5,6,7]:\n",
    "                prediction.append(word_map[i])\n",
    "                i += 1\n",
    "                if i>=MAX_LEN: break\n",
    "                while pred[i]==start+0.5:\n",
    "                    if not word_map[i] in prediction:\n",
    "                        prediction.append(word_map[i])\n",
    "                    i += 1\n",
    "                    if i>=MAX_LEN: break\n",
    "            else:\n",
    "                i += 1\n",
    "            prediction = [x for x in prediction if x!=-1]\n",
    "            if len(prediction)>4:\n",
    "                all_predictions.append( (n, target_map_rev[int(start)], \n",
    "                                ' '.join([str(x) for x in prediction]) ) )\n",
    "                \n",
    "    # MAKE DATAFRAME\n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    df.columns = ['id','class','predictionstring']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54d44ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:22.904316Z",
     "iopub.status.busy": "2022-03-13T02:34:22.903668Z",
     "iopub.status.idle": "2022-03-13T02:34:46.783397Z",
     "shell.execute_reply": "2022-03-13T02:34:46.783821Z",
     "shell.execute_reply.started": "2022-03-13T02:00:43.051309Z"
    },
    "papermill": {
     "duration": 23.92764,
     "end_time": "2022-03-13T02:34:46.783981",
     "exception": false,
     "start_time": "2022-03-13T02:34:22.856341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50B3435E475B</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50B3435E475B</td>\n",
       "      <td>Position</td>\n",
       "      <td>63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50B3435E475B</td>\n",
       "      <td>Claim</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50B3435E475B</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>88 89 90 91 92 93 94 95 96 97 98 99 100 101 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50B3435E475B</td>\n",
       "      <td>Claim</td>\n",
       "      <td>162 163 164 165 166 167 168 169 170 171 172 17...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     class                                   predictionstring\n",
       "0  50B3435E475B      Lead  3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...\n",
       "1  50B3435E475B  Position             63 64 65 66 67 68 69 70 71 72 73 74 75\n",
       "2  50B3435E475B     Claim                76 77 78 79 80 81 82 83 84 85 86 87\n",
       "3  50B3435E475B  Evidence  88 89 90 91 92 93 94 95 96 97 98 99 100 101 10...\n",
       "4  50B3435E475B     Claim  162 163 164 165 166 167 168 169 170 171 172 17..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ba63dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:46.882512Z",
     "iopub.status.busy": "2022-03-13T02:34:46.880949Z",
     "iopub.status.idle": "2022-03-13T02:34:46.886802Z",
     "shell.execute_reply": "2022-03-13T02:34:46.887399Z",
     "shell.execute_reply.started": "2022-03-13T02:01:06.111122Z"
    },
    "papermill": {
     "duration": 0.05731,
     "end_time": "2022-03-13T02:34:46.887566",
     "exception": false,
     "start_time": "2022-03-13T02:34:46.830256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following classes are present in oof preds:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Lead', 'Position', 'Claim', 'Evidence', 'Concluding Statement',\n",
       "       'Counterclaim', 'Rebuttal'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The following classes are present in oof preds:')\n",
    "oof['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a00570",
   "metadata": {
    "papermill": {
     "duration": 0.046825,
     "end_time": "2022-03-13T02:34:46.981271",
     "exception": false,
     "start_time": "2022-03-13T02:34:46.934446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Compute Validation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66ddb3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:47.091977Z",
     "iopub.status.busy": "2022-03-13T02:34:47.090399Z",
     "iopub.status.idle": "2022-03-13T02:34:47.092583Z",
     "shell.execute_reply": "2022-03-13T02:34:47.092988Z",
     "shell.execute_reply.started": "2022-03-13T02:01:06.121202Z"
    },
    "papermill": {
     "duration": 0.064235,
     "end_time": "2022-03-13T02:34:47.093108",
     "exception": false,
     "start_time": "2022-03-13T02:34:47.028873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CODE FROM : Rob Mulla @robikscube\n",
    "# https://www.kaggle.com/robikscube/student-writing-competition-twitch\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0e85f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:47.208415Z",
     "iopub.status.busy": "2022-03-13T02:34:47.207809Z",
     "iopub.status.idle": "2022-03-13T02:34:47.214559Z",
     "shell.execute_reply": "2022-03-13T02:34:47.214071Z",
     "shell.execute_reply.started": "2022-03-13T02:01:06.138218Z"
    },
    "papermill": {
     "duration": 0.075083,
     "end_time": "2022-03-13T02:34:47.214666",
     "exception": false,
     "start_time": "2022-03-13T02:34:47.139583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VALID DATAFRAME\n",
    "valid = train.loc[train['id'].isin(IDS[valid_idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "432ba609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:47.314788Z",
     "iopub.status.busy": "2022-03-13T02:34:47.314067Z",
     "iopub.status.idle": "2022-03-13T02:34:49.978568Z",
     "shell.execute_reply": "2022-03-13T02:34:49.977974Z",
     "shell.execute_reply.started": "2022-03-13T02:01:06.174937Z"
    },
    "papermill": {
     "duration": 2.717212,
     "end_time": "2022-03-13T02:34:49.978711",
     "exception": false,
     "start_time": "2022-03-13T02:34:47.261499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.822571893651655\n",
      "Position 0.6911814776983316\n",
      "Claim 0.6246102681355228\n",
      "Evidence 0.7119193791266072\n",
      "Concluding Statement 0.8138433515482696\n",
      "Counterclaim 0.5210084033613446\n",
      "Rebuttal 0.4174135723431498\n",
      "\n",
      "Overall 0.6575069065521257\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "CLASSES = oof['class'].unique()\n",
    "for c in CLASSES:\n",
    "    pred_df = oof.loc[oof['class']==c].copy()\n",
    "    gt_df = valid.loc[valid['discourse_type']==c].copy()\n",
    "    f1 = score_feedback_comp(pred_df, gt_df)\n",
    "    print(c,f1)\n",
    "    f1s.append(f1)\n",
    "print()\n",
    "print('Overall',np.mean(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2d953",
   "metadata": {
    "papermill": {
     "duration": 0.0542,
     "end_time": "2022-03-13T02:34:50.088395",
     "exception": false,
     "start_time": "2022-03-13T02:34:50.034195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Test Data\n",
    "We will now infer the test data and create a submission. Our CV is 0.633, let's see what our LB is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecc14b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:50.199122Z",
     "iopub.status.busy": "2022-03-13T02:34:50.197018Z",
     "iopub.status.idle": "2022-03-13T02:34:50.205932Z",
     "shell.execute_reply": "2022-03-13T02:34:50.206494Z",
     "shell.execute_reply.started": "2022-03-13T02:01:08.438961Z"
    },
    "papermill": {
     "duration": 0.065457,
     "end_time": "2022-03-13T02:34:50.206653",
     "exception": false,
     "start_time": "2022-03-13T02:34:50.141196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 test texts.\n"
     ]
    }
   ],
   "source": [
    "# GET TEST TEXT IDS\n",
    "files = os.listdir('../input/feedback-prize-2021/test')\n",
    "TEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\n",
    "print('There are',len(TEST_IDS),'test texts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab0a5f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:50.321129Z",
     "iopub.status.busy": "2022-03-13T02:34:50.316359Z",
     "iopub.status.idle": "2022-03-13T02:34:50.358901Z",
     "shell.execute_reply": "2022-03-13T02:34:50.358457Z",
     "shell.execute_reply.started": "2022-03-13T02:01:08.449383Z"
    },
    "papermill": {
     "duration": 0.097836,
     "end_time": "2022-03-13T02:34:50.359018",
     "exception": false,
     "start_time": "2022-03-13T02:34:50.261182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONVERT TEST TEXT TO TOKENS\n",
    "test_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n",
    "test_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n",
    "\n",
    "for id_num in range(len(TEST_IDS)):\n",
    "        \n",
    "    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n",
    "    n = TEST_IDS[id_num]\n",
    "    name = f'../input/feedback-prize-2021/test/{n}.txt'\n",
    "    txt = open(name, 'r').read()\n",
    "    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
    "                                   truncation=True, return_offsets_mapping=True)\n",
    "    test_tokens[id_num,] = tokens['input_ids']\n",
    "    test_attention[id_num,] = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7c00f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T02:34:50.472762Z",
     "iopub.status.busy": "2022-03-13T02:34:50.471839Z",
     "iopub.status.idle": "2022-03-13T02:34:52.450255Z",
     "shell.execute_reply": "2022-03-13T02:34:52.450707Z",
     "shell.execute_reply.started": "2022-03-13T02:01:08.492760Z"
    },
    "papermill": {
     "duration": 2.03799,
     "end_time": "2022-03-13T02:34:52.450862",
     "exception": false,
     "start_time": "2022-03-13T02:34:50.412872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s\n",
      "1/1 - 1s\n",
      "1/1 - 1s\n",
      "Test predictions shape: (5, 1024, 15)\n"
     ]
    }
   ],
   "source": [
    "# INFER TEST TEXTS\n",
    "p = model1.predict([test_tokens, test_attention], \n",
    "                  batch_size=16, verbose=2) / 3\n",
    "p += model2.predict([test_tokens, test_attention], \n",
    "                  batch_size=16, verbose=2) / 3\n",
    "p += model3.predict([test_tokens, test_attention], \n",
    "                  batch_size=16, verbose=2) / 3\n",
    "print('Test predictions shape:',p.shape)\n",
    "test_preds = np.argmax(p,axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 765.687646,
   "end_time": "2022-03-13T02:34:57.102719",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-13T02:22:11.415073",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
